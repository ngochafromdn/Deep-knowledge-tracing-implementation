{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4df586-d42e-49e4-9b77-232780575069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd89ea4e-13d8-4923-8aa2-9c9f3daed5fd",
   "metadata": {},
   "source": [
    "# Import data and data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6650e50-e1a0-4a7f-bf30-006d25e4cb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>log_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478035</td>\n",
       "      <td>7014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478043</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478053</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478069</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50964</td>\n",
       "      <td>167478041</td>\n",
       "      <td>7014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     log_id  sequence_id  correct\n",
       "0    50121  167478035         7014      0.0\n",
       "1    50121  167478043         7014      1.0\n",
       "2    50121  167478053         7014      1.0\n",
       "3    50121  167478069         7014      1.0\n",
       "4    50964  167478041         7014      1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('2015_100_skill_builders_main_problems.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4f9b34-5519-469f-98ae-de6c02ca0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptive_stats(data):\n",
    "    # Compute basic statistics\n",
    "    stats = data.describe()\n",
    "    \n",
    "    # Compute additional statistics\n",
    "    distinct_counts = data.nunique()\n",
    "    \n",
    "    return distinct_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce50d8d-b0cf-495e-b5fd-3a5950d19db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         19917\n",
       "log_id         708631\n",
       "sequence_id       100\n",
       "correct            11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_descriptive_stats(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc2ed5-44dd-4269-87e5-dc764262165f",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb30a9e-c218-4518-aa09-6bbc20257c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>log_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478035</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478043</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478053</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50121</td>\n",
       "      <td>167478069</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50964</td>\n",
       "      <td>167478041</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     log_id  sequence_id  correct\n",
       "0    50121  167478035           26      0.0\n",
       "1    50121  167478043           26      1.0\n",
       "2    50121  167478053           26      1.0\n",
       "3    50121  167478069           26      1.0\n",
       "4    50964  167478041           26      1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sequence_id'] = data['sequence_id'].rank(method='dense').astype(int)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e31bde-4e65-42f2-90a4-06a9be6a70b2",
   "metadata": {},
   "source": [
    "## Convert the raw data to train-data and test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfb53f4-8d07-404b-9f06-f4f234ef3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_data_from_csv(read_file, write_train, write_test):\n",
    "    df = pd.read_csv(read_file)\n",
    "    df['sequence_id'] = df['sequence_id'].rank(method='dense').astype(int)\n",
    "    ui_df = df.groupby(['user_id'], sort=False)\n",
    "    user_inters = []\n",
    "    for ui in ui_df:\n",
    "        tmp_inter = ui[1]\n",
    "        tmp_seq_len = len(tmp_inter)  # Ensure `len` is not reassigned\n",
    "        tmp_questions = [str(x) for x in list(tmp_inter['sequence_id'])]\n",
    "        tmp_ans = ['1' if x == 1.0 else '0' for x in list(tmp_inter['correct'])]\n",
    "        user_inters.append([str(tmp_seq_len), tmp_questions, tmp_ans])\n",
    "\n",
    "    train = user_inters[: int(0.8 * len(user_inters))]\n",
    "    test = user_inters[int(0.8 * len(user_inters)) :]\n",
    "    write_datafile(write_train, train)\n",
    "    write_datafile(write_test, test)\n",
    "    return\n",
    "\n",
    "def write_datafile(file, data):\n",
    "    with open(file, 'w') as f:\n",
    "        for index, dd in enumerate(data):\n",
    "            if index == 0:\n",
    "                continue  # Skip writing the header for the first row\n",
    "            row = [str(dd[0]), ','.join(dd[1]), ','.join(dd[2])]\n",
    "            for item in row:\n",
    "                f.write(item + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    read_data_from_csv('2015_100_skill_builders_main_problems.csv', 'train-data.csv', 'test-data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e41d2-6f81-40d1-afff-3599bb909f62",
   "metadata": {},
   "source": [
    "The provided code defines a class called RNN that represents a Recurrent Neural Network. The class has methods for building, training, and evaluating the RNN model. It uses linear layers, activation functions, and loss functions from the Torch library. The code also includes functions for saving and loading the model, calculating gradients, and performing forward propagation. The RNN class is initialized with parameters such as the number of questions, hidden units, dropout settings, and maximum steps. The code demonstrates how to create, train, and use an RNN model for sequential data analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac96eb-5484-4fbd-8c83-707b8e7d7b2c",
   "metadata": {},
   "source": [
    "# Data loader and Read data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29506984-3518-4045-8768-f7370300b289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Data/dataloader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Data/dataloader.py\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from Data.readdata import DataReader\n",
    "\n",
    "\n",
    "def getDataLoader(batch_size, num_of_questions, max_step):\n",
    "    handle = DataReader('train-data.csv',\n",
    "                        'test-data.csv', max_step,\n",
    "                        num_of_questions)\n",
    "    dtrain = torch.tensor(handle.getTrainData().astype(float).tolist(),\n",
    "                          dtype=torch.float32)\n",
    "    dtest = torch.tensor(handle.getTestData().astype(float).tolist(),\n",
    "                         dtype=torch.float32)\n",
    "    trainLoader = Data.DataLoader(dtrain, batch_size=batch_size, shuffle=True)\n",
    "    testLoader = Data.DataLoader(dtest, batch_size=batch_size, shuffle=False)\n",
    "    return trainLoader, testLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f700c98a-b295-4124-9423-73b6040c51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Data/readdata.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Data/readdata.py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "class DataReader():\n",
    "    def __init__(self, train_path, test_path, maxstep, numofques):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.maxstep = maxstep\n",
    "        self.numofques = numofques\n",
    "\n",
    "    def getData(self, file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for len, ques, ans in itertools.zip_longest(*[file] * 3):\n",
    "                len = int(len.strip().strip(','))\n",
    "                ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                slices = len//self.maxstep + (1 if len % self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    temp = temp = np.zeros(shape=[self.maxstep, 2 * self.numofques])\n",
    "                    if len > 0:\n",
    "                        if len >= self.maxstep:\n",
    "                            steps = self.maxstep\n",
    "                        else:\n",
    "                            steps = len\n",
    "                        for j in range(steps):\n",
    "                            if ans[i*self.maxstep + j] == 1:\n",
    "                                temp[j][ques[i*self.maxstep + j]] = 1\n",
    "                            else:\n",
    "                                temp[j][ques[i*self.maxstep + j] + self.numofques] = 1\n",
    "                        len = len - self.maxstep\n",
    "                    data.append(temp.tolist())\n",
    "            print('done: ' + str(np.array(data).shape))\n",
    "        return data\n",
    "\n",
    "    def getTrainData(self):\n",
    "        print('loading train data...')\n",
    "        trainData = self.getData(self.train_path)\n",
    "        return np.array(trainData)\n",
    "\n",
    "    def getTestData(self):\n",
    "        print('loading test data...')\n",
    "        testData = self.getData(self.test_path)\n",
    "        return np.array(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17170d06-1432-4a7c-8b1b-857f2fa3979c",
   "metadata": {},
   "source": [
    "Overall, this code trains an RNN model on the provided data and saves the trained model and training progress to files. It uses semi-sorted mini-batches for training and evaluates the model's accuracy on the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924127fd-b702-47e1-8cd5-feab5ef45695",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2c067f-5ee5-4a95-a5e8-fe9ab15bc15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/DKT/RNNModel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/DKT/RNNModel.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, device):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=self.device)\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        res = self.sig(self.fc(out))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143e14c-c01a-41c7-a3e4-60b60479d63d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ee00d-22bf-4ea1-80e1-9c1715b1c674",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "1. performance(ground_truth, prediction): Calculates and prints evaluation metrics such as AUC, F1 score, recall, and precision based on the ground truth labels and predicted probabilities.\n",
    "\n",
    "\n",
    "2. lossFunc(num_of_questions, max_step, device): Implements a custom loss function for the DKT model. Computes the loss, prediction, and ground truth tensors for evaluation.\n",
    "\n",
    "\n",
    "3. train_epoch(model, trainLoader, optimizer, loss_func, device): Performs a single training epoch. Computes forward pass, loss, backpropagation, and updates model parameters.\n",
    "\n",
    "\n",
    "4. test_epoch(model, testLoader, loss_func, device): Evaluates the DKT model on test data. Computes forward pass, loss, and collects predicted probabilities and ground truth labels. Prints evaluation metrics using performance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f64a6-6fa6-4490-9a6d-ebb38eb8bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Evaluation/eval.py\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "\n",
    "logger = logging.getLogger('main.eval')\n",
    "\n",
    "\n",
    "def performance(ground_truth, prediction):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(ground_truth.detach().cpu().numpy(),\n",
    "                                             prediction.detach().cpu().numpy())\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    f1 = metrics.f1_score(ground_truth.detach().cpu().numpy(),\n",
    "                          torch.round(prediction).detach().cpu().numpy())\n",
    "    recall = metrics.recall_score(ground_truth.detach().cpu().numpy(),\n",
    "                                  torch.round(prediction).detach().cpu().numpy())\n",
    "    precision = metrics.precision_score(\n",
    "        ground_truth.detach().cpu().numpy(),\n",
    "        torch.round(prediction).detach().cpu().numpy())\n",
    "    logger.info('auc: ' + str(auc) + ' f1: ' + str(f1) + ' recall: ' +\n",
    "                str(recall) + ' precision: ' + str(precision))\n",
    "    print('auc: ' + str(auc) + ' f1: ' + str(f1) + ' recall: ' + str(recall) +\n",
    "          ' precision: ' + str(precision))\n",
    "\n",
    "\n",
    "class lossFunc(nn.Module):\n",
    "    def __init__(self, num_of_questions, max_step, device):\n",
    "        super(lossFunc, self).__init__()\n",
    "        self.crossEntropy = nn.BCELoss()\n",
    "        self.num_of_questions = num_of_questions\n",
    "        self.max_step = max_step\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, pred, batch):\n",
    "        loss = 0\n",
    "        prediction = torch.tensor([], device=self.device)\n",
    "        ground_truth = torch.tensor([], device=self.device)\n",
    "        for student in range(pred.shape[0]):\n",
    "            delta = batch[student][:, 0:self.num_of_questions] + batch[\n",
    "                student][:, self.num_of_questions:]  # shape: [length, questions]\n",
    "            temp = pred[student][:self.max_step - 1].mm(delta[1:].t())\n",
    "            index = torch.tensor([[i for i in range(self.max_step - 1)]],\n",
    "                                 dtype=torch.long, device=self.device)\n",
    "            p = temp.gather(0, index)[0]\n",
    "            a = (((batch[student][:, 0:self.num_of_questions] -\n",
    "                   batch[student][:, self.num_of_questions:]).sum(1) + 1) //\n",
    "                 2)[1:]\n",
    "            for i in range(len(p) - 1, -1, -1):\n",
    "                if p[i] > 0:\n",
    "                    p = p[:i + 1]\n",
    "                    a = a[:i + 1]\n",
    "                    break\n",
    "            loss += self.crossEntropy(p, a)\n",
    "            prediction = torch.cat([prediction, p])\n",
    "            ground_truth = torch.cat([ground_truth, a])\n",
    "        return loss, prediction, ground_truth\n",
    "\n",
    "\n",
    "def train_epoch(model, trainLoader, optimizer, loss_func, device):\n",
    "    model.to(device)\n",
    "    for batch in tqdm.tqdm(trainLoader, desc='Training:    ', mininterval=2):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        loss, prediction, ground_truth = loss_func(pred, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model, optimizer\n",
    "\n",
    "def test_epoch(model, testLoader, loss_func, device):\n",
    "    model.to(device)\n",
    "    ground_truth = torch.tensor([], device=device)\n",
    "    prediction = torch.tensor([], device=device)\n",
    "    for batch in tqdm.tqdm(testLoader, desc='Testing:     ', mininterval=2):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        loss, p, a = loss_func(pred, batch)\n",
    "        prediction = torch.cat([prediction, p])\n",
    "        ground_truth = torch.cat([ground_truth, a])\n",
    "    performance(ground_truth, prediction)\n",
    "    return prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4880cc-9c2c-4e67-9cb0-9df26776d362",
   "metadata": {},
   "source": [
    "# Write main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d05e54f-b45a-47d3-8b7b-322a3152ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.py\n",
    "\n",
    "\"\"\"\n",
    "Usage:\n",
    "    run.py rnn --hidden=<h> [options]\n",
    "\n",
    "Options:\n",
    "    --length=<int>                      max length of question sequence [default: 50]\n",
    "    --questions=<int>                   num of question [default: 150]\n",
    "    --lr=<float>                        learning rate [default: 0.001]\n",
    "    --bs=<int>                          batch size [default: 64]\n",
    "    --seed=<int>                        random seed [default: 13]\n",
    "    --epochs=<int>                      number of epochs [default: 2]\n",
    "    --cuda=<int>                        use GPU id [default: 0]\n",
    "    --hidden=<int>                      dimension of hidden state [default: 50]\n",
    "    --layers=<int>                      layers of rnn [default: 4]\n",
    "    --dropout=<float>                   dropout rate [default: 0.1]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from docopt import docopt\n",
    "from Data.dataloader import getDataLoader\n",
    "from Evaluation import eval\n",
    "\n",
    "\n",
    "def setup_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    args = docopt(__doc__)\n",
    "    length = int(args['--length'])\n",
    "    questions = int(args['--questions'])\n",
    "    lr = float(args['--lr'])\n",
    "    bs = int(args['--bs'])\n",
    "    seed = int(args['--seed'])\n",
    "    epochs = int(args['--epochs'])\n",
    "    cuda = args['--cuda']\n",
    "    hidden = int(args['--hidden'])\n",
    "    layers = int(args['--layers'])\n",
    "    dropout = float(args['--dropout'])\n",
    "    model_type = 'RNN'\n",
    "\n",
    "    logger = logging.getLogger('main')\n",
    "    logger.setLevel(level=logging.DEBUG)\n",
    "    date = datetime.now()\n",
    "    setup_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    trainLoader, testLoader = getDataLoader(bs, questions, length)\n",
    "\n",
    "    from model.DKT.RNNModel import RNNModel\n",
    "    model = RNNModel(questions * 2, hidden, layers, questions, device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_func = eval.lossFunc(questions, length, device)\n",
    "\n",
    "    predicted_var = None  # Initialize a variable to store the predicted variable\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('epoch: ' + str(epoch))\n",
    "        model, optimizer = eval.train_epoch(model, trainLoader, optimizer,\n",
    "                                          loss_func, device)\n",
    "        logger.info(f'epoch {epoch}')\n",
    "\n",
    "    # Save the model\n",
    "    model_dir = 'Result'  \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, 'model.pth')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01f93f0e-f631-4796-b390-dca1225485c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n",
      "done: (22037, 50, 300)\n",
      "loading test data...\n",
      "done: (4691, 50, 300)\n",
      "epoch: 0\n",
      "Training:    : 100%|██████████████████████████| 345/345 [00:17<00:00, 19.93it/s]\n",
      "epoch: 1\n",
      "Training:    : 100%|██████████████████████████| 345/345 [00:17<00:00, 20.11it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyenhoangngocha21/Documents/GitHub/Knowledge-tracing-model/run.py\", line 96, in <module>\n",
      "    main()\n",
      "  File \"/Users/nguyenhoangngocha21/Documents/GitHub/Knowledge-tracing-model/run.py\", line 91, in main\n",
      "    return predicted_values\n",
      "NameError: name 'predicted_values' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python run.py rnn --hidden=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b663af11-4b3e-481e-926d-37fa8ce48ca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mnumber_input(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput dimension\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m test_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_of_questions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Perform prediction\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     model \u001b[38;5;241m=\u001b[39m RNNModel(input_dim, hidden_dim, layer_dim, output_dim, device)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(train_file, test_file, max_step, num_of_questions)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(train_file, test_file, max_step, num_of_questions):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mData\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m readdata\n\u001b[0;32m---> 12\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[43mDataReader\u001b[49m(train_file, test_file, max_step, num_of_questions)\n\u001b[1;32m     13\u001b[0m     dtest \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(handle\u001b[38;5;241m.\u001b[39mgetTestData()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     14\u001b[0m     test_loader \u001b[38;5;241m=\u001b[39m Data\u001b[38;5;241m.\u001b[39mDataLoader(dtest, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataReader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from Data.dataloader import getDataLoader\n",
    "from model.DKT.RNNModel import RNNModel\n",
    "from Evaluation.eval import performance, lossFunc\n",
    "\n",
    "# Function to load and preprocess the data\n",
    "def load_data(train_file, test_file, max_step, num_of_questions):\n",
    "    from Data.readdata import readdata\n",
    "    handle = DataLoader(train_file, test_file, max_step, num_of_questions)\n",
    "    dtest = torch.tensor(handle.getTestData().astype(float).tolist(), dtype=torch.float32)\n",
    "    test_loader = Data.DataLoader(dtest, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "# Function to perform prediction\n",
    "def predict(model, test_loader, num_of_questions):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    prediction = torch.tensor([], device=device)\n",
    "    ground_truth = torch.tensor([], device=device)\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        prediction = torch.cat([prediction, pred])\n",
    "        ground_truth = torch.cat([ground_truth, batch[:, :, :num_of_questions].sum(dim=1)])\n",
    "\n",
    "    return prediction, ground_truth\n",
    "\n",
    "# Function to display performance metrics\n",
    "def display_performance(ground_truth, prediction):\n",
    "    st.subheader('Performance Metrics')\n",
    "    performance(ground_truth, prediction)\n",
    "\n",
    "# Function to recommend items\n",
    "def recommend_items():\n",
    "    # Add your recommendation logic here\n",
    "    # You can display recommended items based on the prediction or any other recommendation algorithm\n",
    "\n",
    "    st.subheader('Recommendation')\n",
    "    # Display recommended items\n",
    "\n",
    "# Main Streamlit web application code\n",
    "st.title('DKT Model Evaluation and Recommendation System')\n",
    "st.sidebar.title('Configuration')\n",
    "\n",
    "# Read input files\n",
    "train_file = 'train.data.csv'\n",
    "test_file = 'test.data.csv'\n",
    "\n",
    "# Read parameters from user input or use default values\n",
    "max_step = st.sidebar.number_input('Max length of question sequence', value=50)\n",
    "num_of_questions = st.sidebar.number_input('Number of questions', value=150)\n",
    "input_dim = st.sidebar.number_input('Input dimension', value=300)\n",
    "hidden_dim = st.sidebar.number_input('Hidden dimension', value=50)\n",
    "layer_dim = st.sidebar.number_input('Number of layers', value=4)\n",
    "output_dim = st.sidebar.number_input('Output dimension', value=150)\n",
    "\n",
    "if train_file is not None and test_file is not None:\n",
    "    # Load data\n",
    "    test_loader = load_data(train_file, test_file, max_step, num_of_questions)\n",
    "\n",
    "    # Perform prediction\n",
    "    model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim, device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    prediction, ground_truth = predict(model, test_loader, num_of_questions)\n",
    "\n",
    "    # Display performance metrics\n",
    "    display_performance(ground_truth, prediction)\n",
    "\n",
    "    # Recommend items\n",
    "    recommend_items()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702db053-4017-4e29-98f1-7e7d30d1f572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
